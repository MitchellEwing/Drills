{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Aesthetics.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'. Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Chapter indicator is idiosyncratic.\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels.\n",
    "#nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, 'Carroll'] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, 'Austen'] for sent in persuasion_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the sentences from the 2 novels into 1 dataframe.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5318, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corner</th>\n",
       "      <th>instantly</th>\n",
       "      <th>jar</th>\n",
       "      <th>pen</th>\n",
       "      <th>shape</th>\n",
       "      <th>cake</th>\n",
       "      <th>ball</th>\n",
       "      <th>acquaint</th>\n",
       "      <th>bristle</th>\n",
       "      <th>perception</th>\n",
       "      <th>...</th>\n",
       "      <th>graze</th>\n",
       "      <th>nonsense</th>\n",
       "      <th>english</th>\n",
       "      <th>disappear</th>\n",
       "      <th>thoughtful</th>\n",
       "      <th>lean</th>\n",
       "      <th>moment</th>\n",
       "      <th>green</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  corner instantly jar pen shape cake ball acquaint bristle perception  \\\n",
       "0      0         0   0   0     0    0    0        0       0          0   \n",
       "1      0         0   0   0     0    0    0        0       0          0   \n",
       "2      0         0   0   0     0    0    0        0       0          0   \n",
       "3      0         0   0   0     0    0    0        0       0          0   \n",
       "4      0         0   0   0     0    0    0        0       0          0   \n",
       "\n",
       "      ...     graze nonsense english disappear thoughtful lean moment green  \\\n",
       "0     ...         0        0       0         0          0    0      0     0   \n",
       "1     ...         0        0       0         0          0    0      0     0   \n",
       "2     ...         0        0       0         0          0    0      0     0   \n",
       "3     ...         0        0       0         0          0    0      0     0   \n",
       "4     ...         0        0       0         0          0    0      0     0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 3064 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our dataframe with features. This can take HOURS.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5318, 3064)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "1. Random Forest\n",
    "2. Logistic Regression\n",
    "3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X & Y.\n",
    "X = np.array(word_counts.drop(['text_sentence', 'text_source'], 1))\n",
    "Y = word_counts['text_source']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest.\n",
    "def bow_rf(X, Y):\n",
    "    start_time = time.time()\n",
    "    from sklearn import ensemble\n",
    "    rfc = ensemble.RandomForestClassifier()\n",
    "    train = rfc.fit(X_train, Y_train)\n",
    "    print('Training set score:', rfc.score(X_train, Y_train))\n",
    "    print('Testing set score:', rfc.score(X_test, Y_test))\n",
    "    print('Time taken: {} seconds'.format('%.1f' % (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression.\n",
    "def bow_lr(X, Y):\n",
    "    start_time = time.time()\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lr = LogisticRegression()\n",
    "    train = lr.fit(X_train, Y_train)\n",
    "    print('Shape:', X_train.shape, Y_train.shape)\n",
    "    print('Training set score:', lr.score(X_train, Y_train))\n",
    "    print('Testing set score:', lr.score(X_test, Y_test))\n",
    "    print('Time taken: {} seconds'.format('%.1f' % (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting.\n",
    "def bow_gb(X, Y):\n",
    "    start_time = time.time()\n",
    "    from sklearn import ensemble\n",
    "    clf = ensemble.GradientBoostingClassifier()\n",
    "    train = clf.fit(X_train, Y_train)\n",
    "    print('Training set score:', clf.score(X_train, Y_train))\n",
    "    print('Testing set score:', clf.score(X_test, Y_test))\n",
    "    print('Time taken: {} seconds'.format('%.1f' % (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mewing_user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9871473354231975\n",
      "Testing set score: 0.8961466165413534\n",
      "Time taken: 5.5 seconds\n",
      "Random Forest:\n",
      " None\n",
      "Shape: (3190, 3062) (3190,)\n",
      "Training set score: 0.9579937304075236\n",
      "Testing set score: 0.9158834586466166\n",
      "Time taken: 0.7 seconds\n",
      "Logistic Regression:\n",
      " None\n",
      "Training set score: 0.886833855799373\n",
      "Testing set score: 0.8735902255639098\n",
      "Time taken: 35.5 seconds\n",
      "Gradient Boosting:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Output.\n",
    "print('Random Forest:\\n', bow_rf(X, Y))\n",
    "print('Logistic Regression:\\n', bow_lr(X, Y))\n",
    "print('Gradient Boosting:\\n', bow_gb(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same model, new inputs\n",
    "Feed the model a differnt novel by Jane Austen, _Emma_. Will it be able to distinguish Austen from Carroll with the same level of accuracy if we insert a different sample of Austen's writing? First, we need to process _Emma_ & combine with the Alice data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to\n"
     ]
    }
   ],
   "source": [
    "# Clean the Emma data.\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma)\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse our cleaned data.\n",
    "emma_doc = nlp(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into sentences.\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]\n",
    "\n",
    "# Emma is quite long, let's cut it down to the same length as Alice.\n",
    "emma_sents = emma_sents[0:len(alice_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Build a new Bag of Words data frame for Emma word counts.\n",
    "# We'll use the same common words from Alice and Persuasion.\n",
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "emma_bow = bow_features(emma_sentences, common_words)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.6976137211036539\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1564</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>706</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1564      105\n",
       "Carroll     706      307"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can model it!\n",
    "# Let's use logistic regression again.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, Y_train)\n",
    "\n",
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_Emma_test = np.concatenate((\n",
    "    X_train[Y_train[Y_train=='Carroll'].index],\n",
    "    emma_bow.drop(['text_sentence','text_source'], 1)\n",
    "), axis=0)\n",
    "y_Emma_test = pd.concat([Y_train[Y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
    "\n",
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well look at that!  NLP approaches are generally effective on the same type of material as they were trained on. It looks like this model is actually able to differentiate multiple works by Austen from Alice in Wonderland.  Now the question is whether the model is very good at identifying Austen, or very good at identifying Alice in Wonderland, or both..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 0: Improve Logistic Regression performance of 93%.\n",
    "Options include:\n",
    "1. Other modeling techniques (SVM)\n",
    "2. Create more features that take advantage of the spaCy information (include grammar, phrases, POS, etc).\n",
    "3. Create sentence-level features (number of words, amount of punctuation)\n",
    "4. Including contextual information (length of previous and next sentences, words repeated from 1 sentence to the next, etc).\n",
    "\n",
    "Design models on the test set, or use cross_validation with multiple folds, and see if you can improve accuracy > 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5318, 3064)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corner</th>\n",
       "      <th>instantly</th>\n",
       "      <th>jar</th>\n",
       "      <th>pen</th>\n",
       "      <th>shape</th>\n",
       "      <th>cake</th>\n",
       "      <th>ball</th>\n",
       "      <th>acquaint</th>\n",
       "      <th>bristle</th>\n",
       "      <th>perception</th>\n",
       "      <th>...</th>\n",
       "      <th>graze</th>\n",
       "      <th>nonsense</th>\n",
       "      <th>english</th>\n",
       "      <th>disappear</th>\n",
       "      <th>thoughtful</th>\n",
       "      <th>lean</th>\n",
       "      <th>moment</th>\n",
       "      <th>green</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  corner instantly jar pen shape cake ball acquaint bristle perception  \\\n",
       "0      0         0   0   0     0    0    0        0       0          0   \n",
       "1      0         0   0   0     0    0    0        0       0          0   \n",
       "2      0         0   0   0     0    0    0        0       0          0   \n",
       "3      0         0   0   0     0    0    0        0       0          0   \n",
       "4      0         0   0   0     0    0    0        0       0          0   \n",
       "\n",
       "      ...     graze nonsense english disappear thoughtful lean moment green  \\\n",
       "0     ...         0        0       0         0          0    0      0     0   \n",
       "1     ...         0        0       0         0          0    0      0     0   \n",
       "2     ...         0        0       0         0          0    0      0     0   \n",
       "3     ...         0        0       0         0          0    0      0     0   \n",
       "4     ...         0        0       0         0          0    0      0     0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 3064 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View our features again.\n",
    "df = word_counts\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.6824451410658308\n",
      "Testing set score: 0.6917293233082706\n",
      "Time taken: 89.6 seconds\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "def bow_svc():\n",
    "    start_time = time.time()\n",
    "    from sklearn.svm import SVC\n",
    "    svc = SVC()\n",
    "    train = svc.fit(X_train, Y_train)\n",
    "    print('Training set score:', svc.score(X_train, Y_train))\n",
    "    print('Testing set score:', svc.score(X_test, Y_test))\n",
    "    print('Time taken: {} seconds'.format('%.1f' % (time.time() - start_time)))\n",
    "\n",
    "# View results.\n",
    "print(bow_svc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating more features taking advantage of spaCy info...\n",
    "\n",
    "# Sentence length.\n",
    "df['sentence_length'] = df.text_sentence.map(lambda x: len(x))\n",
    "\n",
    "# Average word length.\n",
    "df['average_word_length'] = [np.mean(\n",
    "    [len(token) for token in df['text_sentence'][i]]) for i in range(0, len(df['text_sentence']))]\n",
    "\n",
    "# Parts of Speech (POS).\n",
    "df['n_propn'] = [sum([1 for x in t if x.pos_ == 'PROPN']) for t in df.text_sentence]\n",
    "df['n_verb'] = [sum([1 for x in t if x.pos_ == 'VERB']) for t in df.text_sentence]\n",
    "df['n_adp'] = [sum([1 for x in t if x.pos_ == 'ADP']) for t in df.text_sentence]\n",
    "df['n_adj'] = [sum([1 for x in t if x.pos_ == 'ADJ']) for t in df.text_sentence]\n",
    "df['n_adv'] = [sum([1 for x in t if x.pos_ == 'ADV']) for t in df.text_sentence]\n",
    "df['n_noun'] = [sum([1 for x in t if x.pos_ == 'NOUN']) for t in df.text_sentence]\n",
    "df['n_sym'] = [sum([1 for x in t if x.pos_ == 'SYM']) for t in df.text_sentence]\n",
    "df['n_num'] = [sum([1 for x in t if x.pos_ == 'NUM']) for t in df.text_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_source</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>corner</th>\n",
       "      <th>instantly</th>\n",
       "      <th>jar</th>\n",
       "      <th>pen</th>\n",
       "      <th>shape</th>\n",
       "      <th>cake</th>\n",
       "      <th>ball</th>\n",
       "      <th>acquaint</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>n_propn</th>\n",
       "      <th>n_verb</th>\n",
       "      <th>n_adp</th>\n",
       "      <th>n_adj</th>\n",
       "      <th>n_adv</th>\n",
       "      <th>n_noun</th>\n",
       "      <th>n_sym</th>\n",
       "      <th>n_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>3.656716</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>3.730159</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>3.393939</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_source                                      text_sentence corner  \\\n",
       "0     Carroll  (Alice, was, beginning, to, get, very, tired, ...      0   \n",
       "1     Carroll  (So, she, was, considering, in, her, own, mind...      0   \n",
       "2     Carroll  (There, was, nothing, so, VERY, remarkable, in...      0   \n",
       "3     Carroll                                      (Oh, dear, !)      0   \n",
       "4     Carroll                         (I, shall, be, late, !, ')      0   \n",
       "\n",
       "  instantly jar pen shape cake ball acquaint  ...  sentence_length  \\\n",
       "0         0   0   0     0    0    0        0  ...               67   \n",
       "1         0   0   0     0    0    0        0  ...               63   \n",
       "2         0   0   0     0    0    0        0  ...               33   \n",
       "3         0   0   0     0    0    0        0  ...                3   \n",
       "4         0   0   0     0    0    0        0  ...                6   \n",
       "\n",
       "  average_word_length n_propn n_verb n_adp n_adj n_adv n_noun n_sym n_num  \n",
       "0            3.656716       2     13     8     3     3     12     0     0  \n",
       "1            3.730159       2     11     8     7     7      8     0     0  \n",
       "2            3.393939       2      5     4     1     6      2     0     0  \n",
       "3            2.333333       0      0     0     0     0      0     0     0  \n",
       "4            2.333333       0      2     0     1     0      0     0     0  \n",
       "\n",
       "[5 rows x 3074 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reordering columns...\n",
    "cols = list(df)\n",
    "cols.insert(0, cols.pop(cols.index('text_source')))\n",
    "cols.insert(1, cols.pop(cols.index('text_sentence')))\n",
    "df = df.loc[:, cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign training & test sets.\n",
    "X = np.array(df.drop(['text_source', 'text_sentence'], 1))\n",
    "Y = df['text_source']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Shape: (3190, 3072) (3190,)\n",
      "Training set score: 0.961755485893417\n",
      "Testing set score: 0.9163533834586466\n",
      "Time taken: 0.7 seconds\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Training set score: 0.9924764890282132\n",
      "Testing set score: 0.8660714285714286\n",
      "Time taken: 0.9 seconds\n",
      "\n",
      "\n",
      "Gradient Boost:\n",
      "Training set score: 0.8949843260188087\n",
      "Testing set score: 0.8773496240601504\n",
      "Time taken: 36.2 seconds\n",
      "\n",
      "\n",
      "Support Vector Classifier:\n",
      "Training set score: 0.6824451410658308\n",
      "Testing set score: 0.6917293233082706\n",
      "Time taken: 66.6 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run models with new dataframe.\n",
    "print('Logistic Regression:')\n",
    "bow_lr(X, Y)\n",
    "print('\\n')\n",
    "\n",
    "print('Random Forest:')\n",
    "bow_rf(X, Y)\n",
    "print('\\n')\n",
    "\n",
    "print('Gradient Boost:')\n",
    "bow_gb(X, Y)\n",
    "print('\\n')\n",
    "\n",
    "print('Support Vector Classifier:')\n",
    "bow_svc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1: Comparing Alice/Persuasion/Austen vs any other work.\n",
    "ie: <br>\n",
    "1. _Alice in Wonderland_ vs any other work\n",
    "2. _Persuasion_ vs any other work\n",
    "3. Austen vs any other work\n",
    "\n",
    "This will involve pulling a new book from the Project Gutenberg corpus (print(gutenberg.fileids()) for a list) and processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persuasion vs Blake.\n",
    "blake = gutenberg.raw('blake-poems.txt')\n",
    "\n",
    "# Cleaning the text.\n",
    "blake = re.sub(r'VOLUME \\w+', '', blake)\n",
    "blake = re.sub(r'CHAPTER \\w+', '', blake)\n",
    "blake = text_cleaner(blake)\n",
    "\n",
    "# Parse the cleaned novels. This can take a bit.\n",
    "blake_doc = nlp(blake)\n",
    "\n",
    "# Group into sentences.\n",
    "blake_sents = [[sent, \"blake\"] for sent in blake_doc.sents]\n",
    "\n",
    "# Persuasion is quite long, let's cut it down to the same length as Blake.\n",
    "persuasion_sents = persuasion_sents[0:len(blake_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(INTRODUCTION, Piping, down, the, valleys, wil...</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(So, I, piped, with, merry, cheer, ., \")</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Piper, ,, pipe, that, song, again)</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(;, \", So, I, piped, :, he, wept, to, hear, ., \")</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0      1\n",
       "0  (SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...  blake\n",
       "1  (INTRODUCTION, Piping, down, the, valleys, wil...  blake\n",
       "2           (So, I, piped, with, merry, cheer, ., \")  blake\n",
       "3                (Piper, ,, pipe, that, song, again)  blake\n",
       "4  (;, \", So, I, piped, :, he, wept, to, hear, ., \")  blake"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the sentences from the 2 novels into 1 dataframe.\n",
    "sentences1 = pd.DataFrame(blake_sents + persuasion_sents)\n",
    "sentences1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the bags.\n",
    "#persuasionwords = bag_of_words(persuasion_doc)\n",
    "blakewords = bag_of_words(blake_doc)\n",
    "\n",
    "# Combine the bags to create a set of unique words.\n",
    "common_words1 = set(persuasionwords + blakewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corner</th>\n",
       "      <th>instantly</th>\n",
       "      <th>wanderer</th>\n",
       "      <th>walketh</th>\n",
       "      <th>pen</th>\n",
       "      <th>ball</th>\n",
       "      <th>vale</th>\n",
       "      <th>acquaint</th>\n",
       "      <th>perception</th>\n",
       "      <th>charter</th>\n",
       "      <th>...</th>\n",
       "      <th>impress'd</th>\n",
       "      <th>nonsense</th>\n",
       "      <th>distrust</th>\n",
       "      <th>disappear</th>\n",
       "      <th>thoughtful</th>\n",
       "      <th>lean</th>\n",
       "      <th>moment</th>\n",
       "      <th>green</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(INTRODUCTION, Piping, down, the, valleys, wil...</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, I, piped, with, merry, cheer, ., \")</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Piper, ,, pipe, that, song, again)</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(;, \", So, I, piped, :, he, wept, to, hear, ., \")</td>\n",
       "      <td>blake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2717 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  corner instantly wanderer walketh pen ball vale acquaint perception charter  \\\n",
       "0      0         0        0       0   0    0    0        0          0       0   \n",
       "1      0         0        0       0   0    0    0        0          0       0   \n",
       "2      0         0        0       0   0    0    0        0          0       0   \n",
       "3      0         0        0       0   0    0    0        0          0       0   \n",
       "4      0         0        0       0   0    0    0        0          0       0   \n",
       "\n",
       "      ...     impress'd nonsense distrust disappear thoughtful lean moment  \\\n",
       "0     ...             0        0        0         0          0    0      0   \n",
       "1     ...             0        0        0         0          0    0      0   \n",
       "2     ...             0        0        0         0          0    0      0   \n",
       "3     ...             0        0        0         0          0    0      0   \n",
       "4     ...             0        0        0         0          0    0      0   \n",
       "\n",
       "  green                                      text_sentence text_source  \n",
       "0     0  (SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...       blake  \n",
       "1     0  (INTRODUCTION, Piping, down, the, valleys, wil...       blake  \n",
       "2     0           (So, I, piped, with, merry, cheer, ., \")       blake  \n",
       "3     0                (Piper, ,, pipe, that, song, again)       blake  \n",
       "4     0  (;, \", So, I, piped, :, he, wept, to, hear, ., \")       blake  \n",
       "\n",
       "[5 rows x 2717 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our dataframe with features. This can take a while to run.\n",
    "word_counts1 = bow_features(sentences1, common_words1)\n",
    "word_counts1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign training & test sets.\n",
    "X = np.array(word_counts1.drop(['text_source', 'text_sentence'], 1))\n",
    "Y = word_counts1['text_source']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Shape: (597, 2715) (597,)\n",
      "Training set score: 0.9882747068676717\n",
      "Testing set score: 0.9147869674185464\n",
      "Time taken: 0.2 seconds\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Training set score: 0.9932998324958124\n",
      "Testing set score: 0.87468671679198\n",
      "Time taken: 0.2 seconds\n",
      "\n",
      "\n",
      "Gradient Boost:\n",
      "Training set score: 0.9179229480737019\n",
      "Testing set score: 0.8596491228070176\n",
      "Time taken: 2.5 seconds\n",
      "\n",
      "\n",
      "Support Vector Classifier:\n",
      "Training set score: 0.5125628140703518\n",
      "Testing set score: 0.48120300751879697\n",
      "Time taken: 3.1 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run models with new dataframe.\n",
    "print('Logistic Regression:')\n",
    "bow_lr(X, Y)\n",
    "print('\\n')\n",
    "\n",
    "print('Random Forest:')\n",
    "bow_rf(X, Y)\n",
    "print('\\n')\n",
    "\n",
    "print('Gradient Boost:')\n",
    "bow_gb(X, Y)\n",
    "print('\\n')\n",
    "\n",
    "print('Support Vector Classifier:')\n",
    "bow_svc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
